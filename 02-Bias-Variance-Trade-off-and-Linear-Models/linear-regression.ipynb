{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "In this notebook, we will learn how to apply Linear regression for predicting the heating load requirements (Y1) of buildings as a function of building parameters (Xs).\n",
    "\n",
    "The attached dataset is taken from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency).\n",
    "\n",
    "To run this code, you will need the following python packages:\n",
    "* numpy\n",
    "* pandas\n",
    "* openpyxl\n",
    "* scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/taher/.pyenv/versions/3.10.6/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /Users/taher/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load the dataset using pandas\n",
    "df = pd.read_excel(\"Energy_Efficiency.xlsx\", engine = 'openpyxl')\n",
    "# Remove any unnamed columns (might occur due to difference in pandas readers)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "# Remove any row with NaNs\n",
    "df = df.dropna(how='all')\n",
    "# Drop Y2 (as we only consider Y1 for regression)\n",
    "df = df.drop('Y2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we will split the dataframe into a training and testing splits with a 70% / 30% ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42) # Random is fixed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>32.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>41.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>32.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>26.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>28.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>28.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1     X2     X3      X4   X5  X6    X7  X8     Y1\n",
       "334  0.62  808.5  367.5  220.50  3.5   4  0.25   1  15.08\n",
       "139  0.64  784.0  343.0  220.50  3.5   5  0.10   2  15.19\n",
       "485  0.90  563.5  318.5  122.50  7.0   3  0.25   5  32.31\n",
       "547  0.79  637.0  343.0  147.00  7.0   5  0.40   1  41.67\n",
       "18   0.79  637.0  343.0  147.00  7.0   4  0.00   0  29.63\n",
       "..    ...    ...    ...     ...  ...  ..   ...  ..    ...\n",
       "71   0.76  661.5  416.5  122.50  7.0   5  0.10   1  32.21\n",
       "106  0.86  588.0  294.0  147.00  7.0   4  0.10   2  26.33\n",
       "270  0.71  710.5  269.5  220.50  3.5   4  0.10   5  10.67\n",
       "435  0.98  514.5  294.0  110.25  7.0   5  0.25   4  28.62\n",
       "102  0.90  563.5  318.5  122.50  7.0   4  0.10   2  28.83\n",
       "\n",
       "[537 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets display a few rows from the training data\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.760354</td>\n",
       "      <td>674.867784</td>\n",
       "      <td>318.636872</td>\n",
       "      <td>178.115456</td>\n",
       "      <td>5.201117</td>\n",
       "      <td>3.500931</td>\n",
       "      <td>0.235940</td>\n",
       "      <td>2.854749</td>\n",
       "      <td>22.050503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.104790</td>\n",
       "      <td>87.758133</td>\n",
       "      <td>43.619254</td>\n",
       "      <td>44.839207</td>\n",
       "      <td>1.750948</td>\n",
       "      <td>1.106502</td>\n",
       "      <td>0.134118</td>\n",
       "      <td>1.544532</td>\n",
       "      <td>10.088187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.660000</td>\n",
       "      <td>612.500000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>759.500000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>43.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4          X5          X6  \\\n",
       "count  537.000000  537.000000  537.000000  537.000000  537.000000  537.000000   \n",
       "mean     0.760354  674.867784  318.636872  178.115456    5.201117    3.500931   \n",
       "std      0.104790   87.758133   43.619254   44.839207    1.750948    1.106502   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.500000    2.000000   \n",
       "25%      0.660000  612.500000  294.000000  147.000000    3.500000    3.000000   \n",
       "50%      0.740000  686.000000  318.500000  220.500000    3.500000    3.000000   \n",
       "75%      0.820000  759.500000  343.000000  220.500000    7.000000    4.000000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.000000    5.000000   \n",
       "\n",
       "               X7          X8          Y1  \n",
       "count  537.000000  537.000000  537.000000  \n",
       "mean     0.235940    2.854749   22.050503  \n",
       "std      0.134118    1.544532   10.088187  \n",
       "min      0.000000    0.000000    6.010000  \n",
       "25%      0.100000    2.000000   12.960000  \n",
       "50%      0.250000    3.000000   17.230000  \n",
       "75%      0.400000    4.000000   31.280000  \n",
       "max      0.400000    5.000000   43.100000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then lets view some statistics\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will extract the models input and targets from both the training and testing dataframes\n",
    "def extract_Xy(df):\n",
    "    df_numpy = df.to_numpy()\n",
    "    return df_numpy[:, :-1], df_numpy[:, -1]\n",
    "\n",
    "X_train, y_train = extract_Xy(df_train)\n",
    "X_test, y_test = extract_Xy(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression via Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we test the linear regression using Scikit-learn's implementation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 8.368261516136105 (RMS: 2.89279475873006)\n",
      "Testing Error: 8.78499323427013 (RMS: 2.9639489257188845)\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn's MSE function, we can compute the training and testing error for our model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "training_error = mean_squared_error(y_train, y_train_predict)\n",
    "print(f\"Training Error: {training_error} (RMS: {training_error**0.5})\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "testing_error = mean_squared_error(y_test, y_test_predict)\n",
    "print(f\"Testing Error: {testing_error} (RMS: {testing_error**0.5})\")\n",
    "\n",
    "#Note: We also display the Root Mean Square error (RMS) since it is more intuitive to compare with the dataset statistics (diplayed using df_train.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 µs ± 6.19 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "LinearRegression().fit(X_train, y_train)\n",
    "# Here we are measuring the training time to compare with our implementation below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_mean_square_error(true, predicted):\n",
    "    #TODO: implement this function to match Scikit-learn's mean_square_error\n",
    "    #Note: both true & predicted will be float numpy arrays\n",
    "    return np.mean((true - predicted)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our_mean_square_error( np.array([  1, 0]), np.array([1,   0]) ) = 0.0\n",
      "our_mean_square_error( np.array([  0, 1]), np.array([1,   0]) ) = 1.0\n",
      "our_mean_square_error( np.array([0.5, 0]), np.array([1, 0.5]) ) = 0.25\n"
     ]
    }
   ],
   "source": [
    "print(f\"{our_mean_square_error( np.array([  1, 0]), np.array([1,   0]) ) = }\") # Should be 0\n",
    "print(f\"{our_mean_square_error( np.array([  0, 1]), np.array([1,   0]) ) = }\") # Should be 1\n",
    "print(f\"{our_mean_square_error( np.array([0.5, 0]), np.array([1, 0.5]) ) = }\") # Should be 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLinearRegression:\n",
    "    def _prepare_inputs(self, X):\n",
    "        # Here, we add a new input with value 1 to each example. It will be multipled by the bias\n",
    "        ones = np.ones((X.shape[0], 1), dtype=X.dtype)\n",
    "        return np.concatenate((ones, X), axis=1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self._prepare_inputs(X) # First, we prepare the inputs\n",
    "        #TODO: compute and store the model weights into self.w\n",
    "        # Note: you can use numpy function and do not use \"numpy.linalg.lstsq\" or \"numpy.linalg.pinv\"\n",
    "        # To compute a square matrix's inverse, you can use \"numpy.linalg.inv\".\n",
    "        # A more stable option to compute \"numpy.linalg.inv(A) @ b\" is using \"numpy.linalg.solve(A, b)\" \n",
    "        \n",
    "        # to calculate the weights, we use the formula w = (X^T * X)^-1 * X^T * y\n",
    "        # @ is the matrix multiplication operator        \n",
    "        self.w = np.linalg.solve(X.T @ X, X.T @ y) \n",
    "        \n",
    "        # Return self to match the behavior of Scikit-Learn's LinearRegression fit()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._prepare_inputs(X) # First, we prepare the inputs\n",
    "        #TODO: Compute and return the predictions given X\n",
    "        # use the model weights stored in self.w to compute the predictions \n",
    "        # @ is the matrix multiplication operator\n",
    "        return X @ self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you can train your model\n",
    "our_model = OurLinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 8.396083444368179 (RMS: 2.897599600422422)\n",
      "Testing Error: 8.839515947385067 (RMS: 2.973132346093101)\n"
     ]
    }
   ],
   "source": [
    "# Using your MSE function, you can compute the training and testing error for our model\n",
    "y_train_predict = our_model.predict(X_train)\n",
    "training_error = our_mean_square_error(y_train, y_train_predict)\n",
    "print(f\"Training Error: {training_error} (RMS: {training_error**0.5})\")\n",
    "y_test_predict = our_model.predict(X_test)\n",
    "testing_error = our_mean_square_error(y_test, y_test_predict)\n",
    "print(f\"Testing Error: {testing_error} (RMS: {testing_error**0.5})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3 µs ± 160 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "OurLinearRegression().fit(X_train, y_train)\n",
    "# Now, you can compare the time of our implementation with Scikit-Learn's. What is your conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write your conclusion about your implementation's performance and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nTraining Time\\nOur implementation: 14.4 µs ± 82.2 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\\nscikit-learn: 301 µs ± 3.14 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\\n\\nPerformance in terms of training error and testing error\\n\\nOur implementation:\\n    Training Error: 8.396083444368179 (RMS: 2.897599600422422)\\n    Testing Error: 8.839515947385067 (RMS: 2.973132346093101)\\n\\nscikit-learn:\\n    Training Error: 8.368261516136105 (RMS: 2.89279475873006)\\n    Testing Error: 8.78499323427013 (RMS: 2.9639489257188845)\\n\\nConclusion:\\nOur implementation is faster than scikit-learn's implementation. However, the performance of both implementations is almost the same.\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Training Time\n",
    "Our implementation: 14.3 µs ± 160 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
    "scikit-learn: 310 µs ± 6.19 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
    "\n",
    "Performance in terms of training error and testing error\n",
    "\n",
    "Our implementation:\n",
    "    Training Error: 8.396083444368179 (RMS: 2.897599600422422)\n",
    "    Testing Error: 8.839515947385067 (RMS: 2.973132346093101)\n",
    "\n",
    "scikit-learn:\n",
    "    Training Error: 8.368261516136105 (RMS: 2.89279475873006)\n",
    "    Testing Error: 8.78499323427013 (RMS: 2.9639489257188845)\n",
    "\n",
    "Conclusion:\n",
    "Our implementation is faster than scikit-learn's implementation. However, the performance of both implementations is almost the same.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd780a10ad03a506e232ec29f104692e8d999a77309c0fc915217df500c72051"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
